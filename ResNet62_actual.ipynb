{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet62_actual.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFTfSxdCk0LulTFtwnvJJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudraser/Sally/blob/main/ResNet62_actual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDl7XrVLXiN3"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ABe7Aq2VNQ",
        "outputId": "ed26a9a8-2444-44cd-8a31-6a2f5d4745fd"
      },
      "source": [
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzgUcz2DXtUa"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kv-NX62gfC"
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6huR3Ll2kdS",
        "outputId": "e8871617-50a8-41cd-f167-9b7b63d5fcb1"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '/data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(size=[32,32], padding=4),                        \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1inimGz2mUg",
        "outputId": "488dbad5-12ae-4c72-937b-f0f76f63ebd9"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VBq_L3N2ovw"
      },
      "source": [
        "class resblock(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels,identity_downsample=None, stride=1):\n",
        "        super(resblock, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv2 = nn.Conv2d(mid_channels,mid_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "        self.conv3 = nn.Conv2d(mid_channels,mid_channels * self.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(mid_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYM3qApj5GmS"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, resblock, layers, image_channels = 3, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        \n",
        "        self.layer1 = self._create_layer(resblock, layers[0], mid_channels=64, stride=1)\n",
        "        self.layer2 = self._create_layer(resblock, layers[1], mid_channels=128, stride=2)\n",
        "        self.layer3 = self._create_layer(resblock, layers[2], mid_channels=256, stride=2)\n",
        "        self.layer4 = self._create_layer(resblock, layers[3], mid_channels=512, stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(512 * 4, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _create_layer(self, resblock, num_residual_blocks, mid_channels, stride):\n",
        "        identity_downsample = None\n",
        "        new_layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != mid_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    mid_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(mid_channels * 4),\n",
        "            )\n",
        "\n",
        "        new_layers.append(\n",
        "            resblock(self.in_channels, mid_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = mid_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            new_layers.append(resblock(self.in_channels, mid_channels))\n",
        "\n",
        "        return nn.Sequential(*new_layers)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M21G-7ZsZqKn"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        \n",
        "        print('{} Epoch {}, Training loss {}'.format(\n",
        "            datetime.datetime.now(), epoch,\n",
        "            loss_train / len(train_loader)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvo7IO0qZrNL"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "model =  ResNet(resblock,[2, 4, 12, 2]).to(device=device)# <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCq8KO5FZyTq",
        "outputId": "751bc635-4952-4e3e-91b4-0902a59fa041"
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25744410,\n",
              " [9408,\n",
              "  64,\n",
              "  64,\n",
              "  4096,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  32768,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  2097152,\n",
              "  2048,\n",
              "  2048,\n",
              "  1048576,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  65536,\n",
              "  32,\n",
              "  512,\n",
              "  16,\n",
              "  160,\n",
              "  10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwUpiGSHaNkM",
        "outputId": "6e50b307-07d5-4408-a9c5-73ac4486e87c"
      },
      "source": [
        "training_loop(  \n",
        "    n_epochs = 90,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-30 12:30:00.658603 Epoch 1, Training loss 1.8042291904349461\n",
            "2021-07-30 12:30:58.450787 Epoch 2, Training loss 1.4775084443104542\n",
            "2021-07-30 12:31:56.128784 Epoch 3, Training loss 1.3230865318756884\n",
            "2021-07-30 12:32:54.335018 Epoch 4, Training loss 1.20119998926092\n",
            "2021-07-30 12:33:52.548158 Epoch 5, Training loss 1.1059494813537354\n",
            "2021-07-30 12:34:50.745905 Epoch 6, Training loss 1.0240936814366703\n",
            "2021-07-30 12:35:49.215547 Epoch 7, Training loss 0.9533801774692048\n",
            "2021-07-30 12:36:47.693157 Epoch 8, Training loss 0.8950349703011915\n",
            "2021-07-30 12:37:45.956202 Epoch 9, Training loss 0.8415937888652772\n",
            "2021-07-30 12:38:44.200811 Epoch 10, Training loss 0.7894658491663311\n",
            "2021-07-30 12:39:42.392475 Epoch 11, Training loss 0.7499651725563552\n",
            "2021-07-30 12:40:40.618425 Epoch 12, Training loss 0.7154842609029901\n",
            "2021-07-30 12:41:38.790718 Epoch 13, Training loss 0.6786657199454125\n",
            "2021-07-30 12:42:37.021717 Epoch 14, Training loss 0.6445671284899992\n",
            "2021-07-30 12:43:35.146742 Epoch 15, Training loss 0.6184060828155263\n",
            "2021-07-30 12:44:33.340803 Epoch 16, Training loss 0.5872276556461363\n",
            "2021-07-30 12:45:31.471019 Epoch 17, Training loss 0.5581548229583999\n",
            "2021-07-30 12:46:29.604894 Epoch 18, Training loss 0.5351258345386561\n",
            "2021-07-30 12:47:28.009363 Epoch 19, Training loss 0.5095697092011456\n",
            "2021-07-30 12:48:26.189866 Epoch 20, Training loss 0.4924362169583435\n",
            "2021-07-30 12:49:24.292647 Epoch 21, Training loss 0.46786976803827773\n",
            "2021-07-30 12:50:22.173158 Epoch 22, Training loss 0.44525195445741533\n",
            "2021-07-30 12:51:20.124058 Epoch 23, Training loss 0.425932709613572\n",
            "2021-07-30 12:52:18.613195 Epoch 24, Training loss 0.40466479460715943\n",
            "2021-07-30 12:53:17.397298 Epoch 25, Training loss 0.3895220057681546\n",
            "2021-07-30 12:54:15.385740 Epoch 26, Training loss 0.36539531518202606\n",
            "2021-07-30 12:55:13.362132 Epoch 27, Training loss 0.3519901406886937\n",
            "2021-07-30 12:56:11.414302 Epoch 28, Training loss 0.33589514846082236\n",
            "2021-07-30 12:57:09.414149 Epoch 29, Training loss 0.32061237829458683\n",
            "2021-07-30 12:58:07.774256 Epoch 30, Training loss 0.311976076668257\n",
            "2021-07-30 12:59:05.580044 Epoch 31, Training loss 0.29349816010316926\n",
            "2021-07-30 13:00:03.467612 Epoch 32, Training loss 0.2800116160088945\n",
            "2021-07-30 13:01:01.349163 Epoch 33, Training loss 0.26659193185284313\n",
            "2021-07-30 13:01:59.305592 Epoch 34, Training loss 0.25163313189087927\n",
            "2021-07-30 13:02:57.302026 Epoch 35, Training loss 0.24368026749233304\n",
            "2021-07-30 13:03:55.507915 Epoch 36, Training loss 0.2342235848957868\n",
            "2021-07-30 13:04:53.404907 Epoch 37, Training loss 0.22192217331246267\n",
            "2021-07-30 13:05:51.383023 Epoch 38, Training loss 0.2132438434492749\n",
            "2021-07-30 13:06:49.463438 Epoch 39, Training loss 0.20666369367533785\n",
            "2021-07-30 13:07:47.330809 Epoch 40, Training loss 0.19709829224840456\n",
            "2021-07-30 13:08:45.558037 Epoch 41, Training loss 0.18525367688930705\n",
            "2021-07-30 13:09:43.966735 Epoch 42, Training loss 0.18128405021660773\n",
            "2021-07-30 13:10:41.978168 Epoch 43, Training loss 0.17110151275420737\n",
            "2021-07-30 13:11:40.059629 Epoch 44, Training loss 0.16819333287653848\n",
            "2021-07-30 13:12:38.047905 Epoch 45, Training loss 0.1521522116396562\n",
            "2021-07-30 13:13:36.061075 Epoch 46, Training loss 0.14943407624340652\n",
            "2021-07-30 13:14:33.802042 Epoch 47, Training loss 0.1466762968410483\n",
            "2021-07-30 13:15:31.940239 Epoch 48, Training loss 0.13762250570419585\n",
            "2021-07-30 13:16:30.084218 Epoch 49, Training loss 0.13923101693965242\n",
            "2021-07-30 13:17:28.067511 Epoch 50, Training loss 0.1314026673236276\n",
            "2021-07-30 13:18:25.790242 Epoch 51, Training loss 0.12149791390923283\n",
            "2021-07-30 13:19:23.677680 Epoch 52, Training loss 0.12121170375774831\n",
            "2021-07-30 13:20:21.990482 Epoch 53, Training loss 0.11783457212293011\n",
            "2021-07-30 13:21:20.032747 Epoch 54, Training loss 0.1106934182454839\n",
            "2021-07-30 13:22:17.849648 Epoch 55, Training loss 0.10564777871136509\n",
            "2021-07-30 13:23:15.618922 Epoch 56, Training loss 0.10600123278882422\n",
            "2021-07-30 13:24:13.486691 Epoch 57, Training loss 0.10016911080026109\n",
            "2021-07-30 13:25:11.375352 Epoch 58, Training loss 0.09675516482078485\n",
            "2021-07-30 13:26:09.676116 Epoch 59, Training loss 0.0930185625913179\n",
            "2021-07-30 13:27:07.527800 Epoch 60, Training loss 0.08936013060245578\n",
            "2021-07-30 13:28:05.250706 Epoch 61, Training loss 0.08833904805369294\n",
            "2021-07-30 13:29:03.152691 Epoch 62, Training loss 0.08941160681802789\n",
            "2021-07-30 13:30:01.167696 Epoch 63, Training loss 0.08267966115339885\n",
            "2021-07-30 13:30:59.400427 Epoch 64, Training loss 0.08290189118993938\n",
            "2021-07-30 13:31:57.202717 Epoch 65, Training loss 0.0783600565754687\n",
            "2021-07-30 13:32:55.153931 Epoch 66, Training loss 0.07425133629878887\n",
            "2021-07-30 13:33:53.133154 Epoch 67, Training loss 0.07486818102143748\n",
            "2021-07-30 13:34:51.130185 Epoch 68, Training loss 0.07140601670611864\n",
            "2021-07-30 13:35:49.132927 Epoch 69, Training loss 0.06887304314169222\n",
            "2021-07-30 13:36:47.061727 Epoch 70, Training loss 0.07121141582115284\n",
            "2021-07-30 13:37:45.099388 Epoch 71, Training loss 0.06619296406770585\n",
            "2021-07-30 13:38:43.124610 Epoch 72, Training loss 0.0619033167166683\n",
            "2021-07-30 13:39:41.163166 Epoch 73, Training loss 0.0667410805080648\n",
            "2021-07-30 13:40:39.795137 Epoch 74, Training loss 0.06203051291220366\n",
            "2021-07-30 13:41:37.920046 Epoch 75, Training loss 0.06042408799428655\n",
            "2021-07-30 13:42:36.151387 Epoch 76, Training loss 0.06126975833171564\n",
            "2021-07-30 13:43:34.121818 Epoch 77, Training loss 0.05383236378299125\n",
            "2021-07-30 13:44:32.378255 Epoch 78, Training loss 0.053646263047157194\n",
            "2021-07-30 13:45:30.590765 Epoch 79, Training loss 0.054854644098333405\n",
            "2021-07-30 13:46:28.490366 Epoch 80, Training loss 0.0560417965267692\n",
            "2021-07-30 13:47:27.031775 Epoch 81, Training loss 0.05325989381950873\n",
            "2021-07-30 13:48:25.778683 Epoch 82, Training loss 0.047007342524160486\n",
            "2021-07-30 13:49:23.901098 Epoch 83, Training loss 0.04710812068226791\n",
            "2021-07-30 13:50:21.937284 Epoch 84, Training loss 0.04979347897981724\n",
            "2021-07-30 13:51:20.131235 Epoch 85, Training loss 0.04681326107767089\n",
            "2021-07-30 13:52:18.155882 Epoch 86, Training loss 0.04571793706839732\n",
            "2021-07-30 13:53:17.413157 Epoch 87, Training loss 0.046522406017128426\n",
            "2021-07-30 13:54:15.854551 Epoch 88, Training loss 0.04396503592108596\n",
            "2021-07-30 13:55:14.155747 Epoch 89, Training loss 0.042476953114615155\n",
            "2021-07-30 13:56:12.388374 Epoch 90, Training loss 0.04423702024237138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2heWoTXaW3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eebc89e-0224-498e-b9b7-d3307f2c7474"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device) \n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.99\n",
            "Accuracy val: 0.77\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}