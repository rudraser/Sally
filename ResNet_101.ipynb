{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGRqQShe3igxHQSE40Fa3i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudraser/Sally/blob/main/ResNet_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lohpr_iaMX7c",
        "outputId": "df997bef-9b4b-4bec-f2e3-f6b79c6c1bc1"
      },
      "source": [
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "          else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irAAHdh2Mcoe"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nDcmvRPZioQi",
        "outputId": "01ece8c0-0f2c-4cce-8445-fd2524ea1a99"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '/data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(size=[32,32], padding=4),                        \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CcidhnznnMR8",
        "outputId": "04f97279-8463-4bbe-c111-fe12c471bfef"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMJRWpvdii7A"
      },
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "    ):\n",
        "        super(block, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels = 3, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlQExUV7rVSd"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        \n",
        "        print('{} Epoch {}, Training loss {}'.format(\n",
        "            datetime.datetime.now(), epoch,\n",
        "            loss_train / len(train_loader)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VdD0lAVr6Ir"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "model =  ResNet(block,[3, 4, 23, 3]).to(device=device)# <1>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nooe2Ao8sJ7E",
        "outputId": "2253d22b-6025-4c15-98c5-15fffbe98bcf"
      },
      "source": [
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42520650,\n",
              " [9408,\n",
              "  64,\n",
              "  64,\n",
              "  4096,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  16384,\n",
              "  64,\n",
              "  64,\n",
              "  36864,\n",
              "  64,\n",
              "  64,\n",
              "  16384,\n",
              "  256,\n",
              "  256,\n",
              "  32768,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  65536,\n",
              "  128,\n",
              "  128,\n",
              "  147456,\n",
              "  128,\n",
              "  128,\n",
              "  65536,\n",
              "  512,\n",
              "  512,\n",
              "  131072,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  262144,\n",
              "  256,\n",
              "  256,\n",
              "  589824,\n",
              "  256,\n",
              "  256,\n",
              "  262144,\n",
              "  1024,\n",
              "  1024,\n",
              "  524288,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  2097152,\n",
              "  2048,\n",
              "  2048,\n",
              "  1048576,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  1048576,\n",
              "  512,\n",
              "  512,\n",
              "  2359296,\n",
              "  512,\n",
              "  512,\n",
              "  1048576,\n",
              "  2048,\n",
              "  2048,\n",
              "  20480,\n",
              "  10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fF9SyHUNsS8M",
        "outputId": "4044a1de-9330-4422-d582-06280f0f1f19"
      },
      "source": [
        "training_loop(  \n",
        "    n_epochs = 70,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 09:16:22.867839 Epoch 1, Training loss 2.1860355815619155\n",
            "2021-07-29 09:17:58.987938 Epoch 2, Training loss 1.7510598006150913\n",
            "2021-07-29 09:19:35.374013 Epoch 3, Training loss 1.5802017069228775\n",
            "2021-07-29 09:21:12.392221 Epoch 4, Training loss 1.5094798551800916\n",
            "2021-07-29 09:22:49.167851 Epoch 5, Training loss 1.4252638354173401\n",
            "2021-07-29 09:24:26.135569 Epoch 6, Training loss 1.324174334249838\n",
            "2021-07-29 09:26:03.186260 Epoch 7, Training loss 1.239900505832394\n",
            "2021-07-29 09:27:39.637845 Epoch 8, Training loss 1.192122862695733\n",
            "2021-07-29 09:29:16.468689 Epoch 9, Training loss 1.1114784996680287\n",
            "2021-07-29 09:30:52.658065 Epoch 10, Training loss 1.042666361688653\n",
            "2021-07-29 09:32:29.799340 Epoch 11, Training loss 1.005896872571667\n",
            "2021-07-29 09:34:06.696465 Epoch 12, Training loss 0.9391157364906253\n",
            "2021-07-29 09:35:43.232438 Epoch 13, Training loss 0.897639959478927\n",
            "2021-07-29 09:37:20.193270 Epoch 14, Training loss 0.854370287388487\n",
            "2021-07-29 09:38:56.407761 Epoch 15, Training loss 0.8138417318044111\n",
            "2021-07-29 09:40:32.412110 Epoch 16, Training loss 0.77752403084122\n",
            "2021-07-29 09:42:08.921282 Epoch 17, Training loss 0.7422544096818056\n",
            "2021-07-29 09:43:44.852614 Epoch 18, Training loss 0.7139377586753167\n",
            "2021-07-29 09:45:21.078810 Epoch 19, Training loss 0.6852084435617832\n",
            "2021-07-29 09:46:57.478813 Epoch 20, Training loss 0.6550872890502596\n",
            "2021-07-29 09:48:33.765931 Epoch 21, Training loss 0.6377524953630879\n",
            "2021-07-29 09:50:10.295681 Epoch 22, Training loss 0.6146087329787062\n",
            "2021-07-29 09:51:46.355473 Epoch 23, Training loss 0.5814209843954772\n",
            "2021-07-29 09:53:22.620781 Epoch 24, Training loss 0.5559272251337233\n",
            "2021-07-29 09:54:58.751489 Epoch 25, Training loss 0.5302313955314933\n",
            "2021-07-29 09:56:34.509860 Epoch 26, Training loss 0.5146001799013037\n",
            "2021-07-29 09:58:10.350161 Epoch 27, Training loss 0.4864982437447209\n",
            "2021-07-29 09:59:46.496511 Epoch 28, Training loss 0.48345397978716187\n",
            "2021-07-29 10:01:22.638388 Epoch 29, Training loss 0.45205994348620515\n",
            "2021-07-29 10:02:58.377915 Epoch 30, Training loss 0.4313787032499948\n",
            "2021-07-29 10:04:34.353531 Epoch 31, Training loss 0.41467615270324987\n",
            "2021-07-29 10:06:10.632180 Epoch 32, Training loss 0.39731579756988283\n",
            "2021-07-29 10:07:46.318765 Epoch 33, Training loss 0.3709415215665422\n",
            "2021-07-29 10:09:22.630436 Epoch 34, Training loss 0.3786786950915061\n",
            "2021-07-29 10:10:58.684361 Epoch 35, Training loss 0.3450674826036329\n",
            "2021-07-29 10:12:34.186478 Epoch 36, Training loss 0.33677545870127884\n",
            "2021-07-29 10:14:10.058477 Epoch 37, Training loss 0.3195606366638332\n",
            "2021-07-29 10:15:46.250510 Epoch 38, Training loss 0.3094457757594945\n",
            "2021-07-29 10:17:22.465052 Epoch 39, Training loss 0.2990700867398621\n",
            "2021-07-29 10:18:58.370674 Epoch 40, Training loss 0.28837777862844566\n",
            "2021-07-29 10:20:35.100981 Epoch 41, Training loss 0.2718881006874239\n",
            "2021-07-29 10:22:11.807171 Epoch 42, Training loss 0.26245207015586935\n",
            "2021-07-29 10:23:48.046738 Epoch 43, Training loss 0.24843400606261495\n",
            "2021-07-29 10:25:24.573198 Epoch 44, Training loss 0.2388637867825263\n",
            "2021-07-29 10:27:01.180502 Epoch 45, Training loss 0.22682033657617962\n",
            "2021-07-29 10:28:37.376444 Epoch 46, Training loss 0.21838171987811014\n",
            "2021-07-29 10:30:13.685089 Epoch 47, Training loss 0.21314109737991982\n",
            "2021-07-29 10:31:50.399070 Epoch 48, Training loss 0.1995636376568957\n",
            "2021-07-29 10:33:26.685953 Epoch 49, Training loss 0.19705698207554306\n",
            "2021-07-29 10:35:02.793113 Epoch 50, Training loss 0.1871841211107743\n",
            "2021-07-29 10:36:39.534595 Epoch 51, Training loss 0.18085751132777586\n",
            "2021-07-29 10:38:16.038887 Epoch 52, Training loss 0.17240612080220677\n",
            "2021-07-29 10:39:52.308953 Epoch 53, Training loss 0.17264318204653994\n",
            "2021-07-29 10:41:28.944800 Epoch 54, Training loss 0.16390295580620198\n",
            "2021-07-29 10:43:05.490189 Epoch 55, Training loss 0.15666776156955686\n",
            "2021-07-29 10:44:41.556265 Epoch 56, Training loss 0.1520286737953115\n",
            "2021-07-29 10:46:18.266885 Epoch 57, Training loss 0.1442282296552816\n",
            "2021-07-29 10:47:54.990513 Epoch 58, Training loss 0.14069599465555166\n",
            "2021-07-29 10:49:31.369166 Epoch 59, Training loss 0.1843113515673734\n",
            "2021-07-29 10:51:07.970201 Epoch 60, Training loss 0.1322001168680618\n",
            "2021-07-29 10:52:44.515203 Epoch 61, Training loss 0.1333505715984289\n",
            "2021-07-29 10:54:20.936895 Epoch 62, Training loss 0.12112765454465661\n",
            "2021-07-29 10:55:57.682434 Epoch 63, Training loss 0.12136017693840254\n",
            "2021-07-29 10:57:34.564081 Epoch 64, Training loss 0.11868631229003476\n",
            "2021-07-29 10:59:11.517551 Epoch 65, Training loss 0.10865538362342188\n",
            "2021-07-29 11:00:47.672240 Epoch 66, Training loss 0.10787255842538784\n",
            "2021-07-29 11:02:24.828702 Epoch 67, Training loss 0.11127612984541546\n",
            "2021-07-29 11:04:02.488920 Epoch 68, Training loss 0.10672729792397308\n",
            "2021-07-29 11:05:39.063617 Epoch 69, Training loss 0.10004219241128268\n",
            "2021-07-29 11:07:16.121312 Epoch 70, Training loss 0.09467096532792653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ygIADJsnj3WQ",
        "outputId": "69972616-e276-455b-962c-614ecb0e1d66"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.96\n",
            "Accuracy val: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}